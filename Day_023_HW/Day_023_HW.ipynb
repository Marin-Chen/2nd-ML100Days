{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>範例 : (Kaggle)房價預測</h1>\n",
    "    \n",
    "以下用房價預測資料, 觀察均值編碼的效果\n",
    "\n",
    "<h1>[教學目標]</h1>\n",
    "\n",
    "以下用房價預測資料, 觀察均值編碼的效果\n",
    "\n",
    "<h1>[範例重點]</h1>\n",
    "\n",
    "觀察標籤編碼與均值編碼, 在特徵數量 / 線性迴歸分數 / 線性迴歸時間上, 分別有什麼影響 (In[3], Out[3], In[4], Out[4])\n",
    "\n",
    "觀察標籤編碼與均值編碼, 在特徵數量 / 梯度提升樹分數 / 梯度提升樹時間上, 分別有什麼影響 (In[5], Out[5], In[6], Out[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做完特徵工程前的所有準備\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = 'D:\\\\2nd-ML100Days\\\\2nd-ML100Days\\\\Day_023_HW\\\\'\n",
    "df_train = pd.read_csv(data_path + 'house_train.csv')\n",
    "df_test = pd.read_csv(data_path + 'house_test.csv')\n",
    "\n",
    "train_Y = np.log1p(df_train['SalePrice'])\n",
    "ids = df_test['Id']\n",
    "df_train = df_train.drop(['Id', 'SalePrice'] , axis=1)\n",
    "df_test = df_test.drop(['Id'] , axis=1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只取類別值 (object) 型欄位, 存於 object_features 中\n",
    "object_features = []\n",
    "for dtype, feature in zip(df.dtypes, df.columns):\n",
    "    if dtype == 'object':\n",
    "        object_features.append(feature)\n",
    "print(f'{len(object_features)} Numeric Features : {object_features}\\n')\n",
    "\n",
    "# 只留類別型欄位\n",
    "df = df[object_features]\n",
    "df = df.fillna('None')\n",
    "train_num = train_Y.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對照組 : 標籤編碼 + 線性迴歸\n",
    "df_temp = pd.DataFrame()\n",
    "for c in df.columns:\n",
    "    df_temp[c] = LabelEncoder().fit_transform(df[c])\n",
    "train_X = df_temp[:train_num]\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值編碼 + 線性迴歸\n",
    "data = pd.concat([df[:train_num], train_Y], axis=1)\n",
    "for c in df.columns:\n",
    "    mean_df = data.groupby([c])['SalePrice'].mean().reset_index()\n",
    "    mean_df.columns = [c, f'{c}_mean']\n",
    "    data = pd.merge(data, mean_df, on=c, how='left')\n",
    "    data = data.drop([c] , axis=1)\n",
    "data = data.drop(['SalePrice'] , axis=1)\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, data, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對照組 : 標籤編碼 + 梯度提升樹\n",
    "df_temp = pd.DataFrame()\n",
    "for c in df.columns:\n",
    "    df_temp[c] = LabelEncoder().fit_transform(df[c])\n",
    "train_X = df_temp[:train_num]\n",
    "estimator = GradientBoostingRegressor()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值編碼 + 梯度提升樹\n",
    "data = pd.concat([df[:train_num], train_Y], axis=1)\n",
    "for c in df.columns:\n",
    "    mean_df = data.groupby([c])['SalePrice'].mean().reset_index()\n",
    "    mean_df.columns = [c, f'{c}_mean']\n",
    "    data = pd.merge(data, mean_df, on=c, how='left')\n",
    "    data = data.drop([c] , axis=1)\n",
    "data = data.drop(['SalePrice'] , axis=1)\n",
    "estimator = GradientBoostingRegressor()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, data, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>作業 : (Kaggle)鐵達尼生存預測</h1>\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "<h1>[作業目標]</h1>\n",
    "\n",
    "試著模仿範例寫法, 在鐵達尼生存預測中, 觀察均值編碼的效果\n",
    "\n",
    "<h1>[作業重點]</h1>\n",
    "\n",
    "仿造範例, 完成標籤編碼與均值編碼搭配邏輯斯迴歸的預測\n",
    "\n",
    "觀察標籤編碼與均值編碼在特徵數量 / 邏輯斯迴歸分數 / 邏輯斯迴歸時間上, 分別有什麼影響 (In[3], Out[3], In[4], Out[4])\n",
    "\n",
    "<h1>作業1</h1>\n",
    "\n",
    "請仿照範例，將鐵達尼範例中的類別型特徵改用均值編碼實作一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做完特徵工程前的所有準備 (與前範例相同)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = 'D:\\\\2nd-ML100Days\\\\2nd-ML100Days\\\\Day_023_HW\\\\'\n",
    "df_train = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "df_test = pd.read_csv(data_path + 'titanic_test.csv')\n",
    "\n",
    "train_Y = df_train['Survived']\n",
    "ids = df_test['PassengerId']\n",
    "df_train = df_train.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df_test = df_test.drop(['PassengerId'] , axis=1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只取類別值 (object) 型欄位, 存於 object_features 中\n",
    "object_features = []\n",
    "for dtype, feature in zip(df.dtypes, df.columns):\n",
    "    if dtype == 'object':\n",
    "        object_features.append(feature)\n",
    "print(f'{len(object_features)} Numeric Features : {object_features}\\n')\n",
    "\n",
    "# 只留類別型欄位\n",
    "df = df[object_features]\n",
    "df = df.fillna('None')\n",
    "train_num = train_Y.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對照組 : 標籤編碼 + 線性迴歸\n",
    "df_temp = pd.DataFrame()\n",
    "for c in df.columns:\n",
    "    df_temp[c] = LabelEncoder().fit_transform(df[c])\n",
    "train_X = df_temp[:train_num]\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值編碼 + 線性迴歸\n",
    "data = pd.concat([df[:train_num], train_Y], axis=1)\n",
    "for c in df.columns:\n",
    "    mean_df = data.groupby([c])['Survived'].mean().reset_index()\n",
    "    mean_df.columns = [c, f'{c}_mean']\n",
    "    data = pd.merge(data, mean_df, on=c, how='left')\n",
    "    data = data.drop([c] , axis=1)\n",
    "data = data.drop(['Survived'] , axis=1)\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, data, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對照組 : 標籤編碼 + 梯度提升樹\n",
    "df_temp = pd.DataFrame()\n",
    "for c in df.columns:\n",
    "    df_temp[c] = LabelEncoder().fit_transform(df[c])\n",
    "train_X = df_temp[:train_num]\n",
    "estimator = GradientBoostingRegressor()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值編碼 + 梯度提升樹\n",
    "data = pd.concat([df[:train_num], train_Y], axis=1)\n",
    "for c in df.columns:\n",
    "    mean_df = data.groupby([c])['Survived'].mean().reset_index()\n",
    "    mean_df.columns = [c, f'{c}_mean']\n",
    "    data = pd.merge(data, mean_df, on=c, how='left')\n",
    "    data = data.drop([c] , axis=1)\n",
    "data = data.drop(['Survived'] , axis=1)\n",
    "estimator = GradientBoostingRegressor()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, data, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>作業2</h1>\n",
    "\n",
    "觀察鐵達尼生存預測中，均值編碼與標籤編碼兩者比較，哪一個效果比較好? 可能的原因是什麼?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對照組 : 標籤編碼 + 邏輯斯迴歸\n",
    "df_temp = pd.DataFrame()\n",
    "for c in df.columns:\n",
    "    df_temp[c] = LabelEncoder().fit_transform(df[c])\n",
    "train_X = df_temp[:train_num]\n",
    "estimator = LogisticRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值編碼 + 邏輯斯迴歸\n",
    "data = pd.concat([df[:train_num], train_Y], axis=1)\n",
    "for c in df.columns:\n",
    "    mean_df = data.groupby([c])['Survived'].mean().reset_index()\n",
    "    mean_df.columns = [c, f'{c}_mean']\n",
    "    data = pd.merge(data, mean_df, on=c, how='left')\n",
    "    data = data.drop([c] , axis=1)\n",
    "data = data.drop(['Survived'] , axis=1)\n",
    "estimator = LogisticRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {train_X.shape}')\n",
    "print(f'score : {cross_val_score(estimator, data, train_Y, cv=5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
